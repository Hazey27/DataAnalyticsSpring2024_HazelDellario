party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
plot(party.tree, type = "simple")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
#alternative method
library("party")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
dev.off
dev.off()
plot(party.tree, type = "simple")
library("tidyverse")
library("tidyverse")
library("randomForest")
library("randomForestExplainer")
install.packages("randomForestExplainer")
library("randomForestExplainer")
library("randomForestSRC")
library("ggRandomForest")
install.packages("ggRandomForest")
library("ggRandomForest")
library("ggRandomForests")
data(Boston, package = "MASS")
Boston$chas <- as.logical(Boston$chas)
str(Boston)
set.seed(125)
rmft <- randomForest(medv ~ ., data = Boston, localImp = T)
rmft
plot(rmft)
#determine ideal mtry value, mtry with least error
mtry <- tuneRF(Boston[-1], Boston$medv, ntreeTry = 500,
stepFactor = 1.5, improve = 0.01, trace = T)
best_mtry <- mtry[mtry[ , 2] == min(mtry[ , 2]), 1]
rmft_mtry <- randomForest(mdev ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry <- randomForest(medv ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry
plot(rmft_mtry)
importance(rmft_mtry)
varImpPlot(rmft_mtry)
#un the explainer
min_depth_frame <- min_depth_distribution(rmft_mtry)
head(min_depth_frame)
plot_min_depth_distribution(min_depth_frame)
plot_min_depth_distribution(min_depth_frame) #very pretty plot
plot_min_depth_distribution(min_depth_frame,
mean_sample = "relevant_trees",
k = 15)
importance_frame <- measure_importance(rmft_mtry)
importance_frame
plot_multi_way_importance(importance_frame, size_measure = "no_of_nodes")
plot_multi_way_importance(importance_frame,
x_measure = "mse_increase",
y_measure = "node_purity_increase",
size_measure = "p_value",
no_of_labels = 5)
plot_importance_ggpairs(importance_frame)
plot_importance_rankings(importance_frame)
vars <- important_variables(importance_frame,
k = 5,
measures = c("mean_min_depth", "no_of_trees"))
interactions_frame <- min_depth_interactions(rmft_mtry, vars)
plot_min_depth_interactions(interactions_frame)
interactions_frame <- min_depth_interactions(rmft_mtry, vars,
mean_sample =  "relevant_trees",
uncond_mean_sample = "relevant_trees")
plot_predict_interaction(rmft_mtry, Boston, "rm", "lstat")
rmftsrc <- rfsrc(medv ~ ., data = Boston)
plot(gg_rfsrc(rmftsrc), alpha = 0.5) + coord_cartesian(ylim = c(5, 49))
plot(gg_vimp(rmftsrc))
vars_src <- var.select(rmftsrc)
gg_md <- gg_minimal_depth(vars_src)
plot(gg_md)
gg_v <- gg_variable(rmftsrc)
xvar <- gg_md$topvars
plot(gg_v, xvar = xvar, panel = T, se = 0.95, span = 1.2, alpha = 0.4) +
labs(y = "medv", x= "")
plot(gg_v, xvar = "chas", points = F,
notch = T, alpha = 0.4) +
labs(y = "medv")
show.plots = F
partial
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T,
sorted = F,
show.plots = F)
partial
partial
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
gg_p <- gg_partial(partial)
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#variable intersection
interaction_src <- find.interaction(rmftsrc)
plot(gg_interaction(interaction_src),
xvar = gg_md$topvars, panel = T)
# Importing
library("caret")
library("janitor")
library("MASS")
library("tidyverse")
library("readxl")
#IMPORTING
library("tidyverse")
library("tuneR")
library("warbleR")
install.packages("warbleR")
sudo ln -s C:/rtools40/ucrt64/bin/../lib/gcc/x86_64-w64-mingw32/10.3.0/../../../../x86_64-w64-mingw32/bin/libfftw3.so.3 /usr/lib/libfftw3.so
g++ --version
library("RTools")
install.packages("RTools")
chooseCRANmirror()
library("warbleR")
install.packages("warbleR")
library("warbleR")
?selection_table
source("~/.active-rstudio-document", echo=TRUE)
plot(mtcars$wt, mtcars$mpg)
qplot(mtcars, mtcars$mpg)
qplot(mtcars$wt, mtcars$mpg)
source("~/.active-rstudio-document", echo=TRUE)
qplot(mtcars$wt, mtcars$mpg)
?qplot
qplot(wt, mpg, data = mtcars)
ggplot(mtcars, aes(x = wt, y = mpg)) +
geom_point()
plot(pressure$temperature, pressure$pressure, type = "l")
points(pressure$temperature, pressure$pressure)
lines(pressure$temperature, pressure$pressure/2, col = "red")
points(pressure$temperature, pressure$pressure/2, col = "blue")
qplot(pressure$temperature, pressure$pressure, geom = 'line')
qplot(temperature, pressure, data = pressure, geom = "line")
ggplot(pressure, aes(x = temperature, y = pressure)) +
geom_line() +
geom_point()
source("~/.active-rstudio-document", echo=TRUE)
barplot(BOD$demand, names.arg = BOD$Time)
table(mtcars$cyl)
barplot(table(mtcars$cyl))
qplot(mtcars$cyl)
qplot(factor(mtcars$cyl))
ggplot(mtcars, aes(x = factor(cyl))) +
geom_bar()
ggplot(mtcars, aes(x = mpg)) +
geom_histogram(binwidth = 4)
ggplot(ToothGrowth, aes(x = supp, y = len)) +
geom_boxplot()
ggplot(ToothGrowth, aes(x = interaction(supp, dose))) +
geom_boxplot()
ggplot(ToothGrowth, aes(x = interaction(supp, dose), y = len)) +
geom_boxplot()
library("installr")
library("rlang")
install.packages("installr")
library("installr")
updateR()
install.packages("knn")
install.packages("kNN")
#run the classifier, can change k
classif<-knn(train,test,cg,k=5)
library('class')
#run the classifier, can change k
classif<-knn(train,test,cg,k=5)
source("C:/Users/Hazel Dellario/Desktop/Homework/data_analysis_private/knn_kmeans_Rscripts/lab2_knn1.R", echo=TRUE)
source("C:/Users/Hazel Dellario/Desktop/Homework/data_analysis_private/knn_kmeans_Rscripts/lab2_knn1.R", echo=TRUE)
source("C:/Users/hazeldellario/Desktop/Homework/data_analysis_private/knn_kmeans_Rscripts/lab2_knn2.R", echo=TRUE)
summary(fit.kknn)
pairs(ionosphere.valid, pch = pcol, col = c("green", "red"))
pairs(ionosphere.valid, pch = pcol, col = c("green", "red"))
source("~/GitHub/DataAnalyticsSpring2024_HazelDellario/Lab 3/lab3_part1.R", echo=TRUE)
View(abalone_data)
View(abalone_data)
sum(which(abalone_data[1:4177, 2:9] > 0))
sum(which(abalone_data[1:4177, 2:9] < 0))
sum(is.na(abalone_data))
?runif
?sample
abalone_val = abalone_val[val_indices]
train_val_indices <- sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.7), replace = FALSE)
abalone_train <- abalone_data[train_val_indices, ]
abalone_test <- abalone_data[-train_val_indices, ]
val_indices = sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.7), replace = FALSE)
abalone_train = abalone_train[-val_indices, ]
abalone_val = abalone_val[val_indices]
abalone_val = abalone_val[val_indices, ]
abalone_val = abalone_data[val_indices, ]
dim(abalone_train)
4177 * .7
4177 * .5
4177 * .2
dim(abalone_val)
val_indices = sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.3), replace = FALSE)
abalone_train = abalone_train[-val_indices, ]
abalone_val = abalone_data[val_indices, ]
dim(abalone_train)
dim(abalone_val)
dim(abalone_test)
1254+1253+630
train_val_indices <- sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.7), replace = FALSE)
abalone_train <- abalone_data[train_val_indices, ]
abalone_test <- abalone_data[-train_val_indices, ]
val_indices = sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.3), replace = FALSE)
abalone_train = abalone_train[-val_indices, ]
abalone_val = abalone_data[val_indices, ]
length(val_indices)
train_val_indices <- sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.7), replace = FALSE)
abalone_train <- abalone_data[train_val_indices, ]
abalone_test <- abalone_data[-train_val_indices, ]
val_indices = sample(1:length(abalone_train$Rings) - 1, size = round(length(abalone_data$Rings) * 0.3), replace = FALSE)
abalone_train = abalone_train[-val_indices, ]
abalone_val = abalone_data[val_indices, ]
length(val_indices)
length(train_val_indices)
4177*.7
4177-1253
4177*.7
4177*.2
4177*.3
train_val_indices <- sample(1:length(abalone_data$Rings) - 1, size = round(length(abalone_data$Rings) * 0.7), replace = FALSE)
abalone_train <- abalone_data[train_val_indices, ]
abalone_test <- abalone_data[-train_val_indices, ]
val_indices = sample(1:length(abalone_train$Rings) - 1, size = round(length(abalone_data$Rings) * 0.3), replace = FALSE)
length(val_indices)
val_indices = sample(1:length(abalone_train$Rings) - 1, size = round(length(abalone_train$Rings) * 0.3), replace = FALSE)
abalone_train = abalone_train[-val_indices, ]
abalone_val = abalone_data[val_indices, ]
4177/2
?kknn
library("kknn")
data(ionosphere)
View(ionosphere)
train_knn = kknn(formula = Rings ~ ., abalone_train, abalone_val, kmax = 5)
?train.kknn
train_knn = kknn(formula = Rings ~ ., abalone_train, kmax = 5)
train_knn = train.kknn(formula = Rings ~ ., abalone_train, kmax = 5)
summary(train_knn)
?pairs
?predict
head(abalone_val[2:8])
abalone_val$p_rings = predict(train_knn, newdata = abalone_val[2:8])
abalone_val[1:8]
abalone_val$p_rings = predict(train_knn, newdata = abalone_val[1:8])
ggplot(abalone_val, aes(x = abalone_val$Rings, y = abalone_val$p_rings)) +
geom_point()
per_correct = sum(which(abalone_val$Rings == abalone_val$p_rings))
per_correct
?ifelse
which(abalone_val$Rings == abalone_val$p_rings)
sum(which(abalone_val$Rings == abalone_val$p_rings))
length(which(abalone_val$Rings == abalone_val$p_rings))
abalone_train[1,]
ggplot(abalone_train, aes(x = length, y = age, color = sex))+
geom_point(aes(size = diameter))
ggplot(abalone_train, aes(x = Length, y = Rings, color = Sex))+
geom_point(aes(size = Diameter))
ggplot(abalone_train, aes(x = Whole.weight, y = Rings, color = shell.weight))+
ggplot(abalone_train, aes(x = Whole.weight, y = Rings, color = shell.weight))+
geom_point(aes(size = Shucked.weight))
ggplot(abalone_train, aes(x = Whole.weight, y = Rings, color = Shell.weight))+
geom_point(aes(size = Shucked.weight))
abalone_train[1,]
ggplot(abalone_train, aes(x = Height, y = Rings, color = Viscera.weight))+
geom_point(aes(size = Diameter))
?rmsd
library("bio3d")
install.packages("bio3d")
library("bio3d")
?rmsd
val_rmsd = rmsd(abalone_val$Rings, abalone_val$p_rings)
val_rmsd
abalone_train$p_rings = predict(train_knn, newdata = abalone_train[1:8])
train_rmsd = rmsd(abalone_train$Rings, abalone_train$p_rings)
train_rmsd
rmsd_diff = val_rmsd - train_rmsd
print(rmsd_diff)
summary(train_knn)
View(train_knn)
factor(abalone_train$Rings, ordered = TRUE)
# Age/Rings is continuous... unless we're treating it as if it's ordinal? oh I guess it is ordinal....
# TREATING RINGS AS ORDINAL
abalone_train$Rings_ord = factor(abalone_train$Rings, ordered = TRUE)
head(abalone_train)
train_knn = train.kknn(formula = Rings ~ ., abalone_train[ , c(1:7, 10)], kmax = 5)
train_knn = train.kknn(formula = Rings_ord ~ ., abalone_train[ , c(1:7, 10)], kmax = 5)
# Age/Rings is continuous... unless we're treating it as if it's ordinal? oh I guess it is ordinal....
# TREATING RINGS AS ORDINAL
abalone_train$Rings_ord = factor(abalone_train$Rings, ordered = TRUE)
abalone_train[1:5, 10]
abalone_train[1, 10]
abalone_train[1, 11]
abalone_train[1, 9]
abalone_train[1, 8]
train_knn = train.kknn(formula = Rings_ord ~ ., abalone_train[ , c(1:8, 11)], kmax = 5)
summary(train_knn)
cont_knn = train.kknn(formula = Rings ~ ., abalone_train, kmax = 5)
ord_knn = train.kknn(formula = Rings_ord ~ ., abalone_train[ , c(1:8, 11)], kmax = 5)
abalone_train$ord_rings = predict(ord_knn, newdata = abalone_train[1:8])
colNames(abalone_val[ , 1:8])
head(abalone_val)
abalone_train$ord_rings = predict(ord_knn, newdata = abalone_train[1:8])
abalone_val$ord_rings = predict(ord_knn, newdata = abalone_val[1:8])
train_ord_rmsd = rmsd(abalone_train$Rings, abalone_train$ord_rings)
train_ord_rmsd = rmsd(abalone_train$Rings, abalone_train$ord_rings)
abalone_train$ord_rings
train_ord_rmsd = rmsd(abalone_train$Rings, as.double(abalone_train$ord_rings))
train_ord_rmsd
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_point()
?geom_jitter
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_point(position = "jitter")
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_point(position = "jitter")
?geom_jitter
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_point(position = "jitter", width = 0.25, height = 0.25)
?geom_jitter
?geom_point
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_jitter(width = 0.25, height = 0.25)
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_jitter(width = 0.4, height = 0.4)
ggplot(abalone_val, aes(x = Rings, y = ord_rings)) +
geom_jitter(width = 0.5, height = 0.5)
abalone_val$correct = ifelse(which(abalone_val$Rings == abalone_val$ord_rings), TRUE, FALSE)
which(abalone_val$Rings == abalone_val$ord_rings)
abalone_val$correct[which(abalone_val$Rings == abalone_val$ord_rings)] = TRUE
head(abalone_val)
abalone_val$correct[-which(abalone_val$Rings == abalone_val$ord_rings)] = FALSE
head(abalone_val)
ggplot(abalone_val, aes(x = Rings, y = ord_rings, color = correct)) +
geom_jitter(width = 0.5, height = 0.5)
ggplot(abalone_val, aes(x = correct, y = Rings)) +
geom_boxplot()
percent_correct = sum(abalone_val$correct) / length(abalone_val$correct)
percent_correct
iris_data = data("iris")
head(iris_data)
iris_data = data(iris)
head(iris_data)
head(iris_data)
data(iris)
head(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
`?kmeans`
?stats::kmeans
?kmeans
data(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[i] = kmeans(iris_data, centers = i, iter.max = 1000)
}
warnings()
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
}
View(kmeans_fits)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 2:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
}
head(iris_data)
head(iris)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
kmeans_fits = list()
for(i in 2:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
library("fdm2id")
install.packages("fdm2id")
install.packages("fdm2id")
source("~/GitHub/DataAnalyticsSpring2024_HazelDellario/Lab 3/lab3_part1.R", echo=TRUE)
library("flexclust")
install.packages("flexclust")
data(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 2:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
predict(kmeans_fits[[1]], newdata = iris_data[ , 1:4])
kmeans_fits[[1]]
View(kmeans_fits)
kmeans_fits[[2]]
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
View(kmeans_fits)
kmeans(iris_data, centers = 2, iter.max = 1000)
kmeans(iris_data, centers = 3, iter.max = 1000)
predict(kmeans_fits[[1]], newdata = iris_data[ , 1:4])
predict(kmeans_fits[[2]], newdata = iris_data[ , 1:4])
predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
?predict
?predict.kmeans
predict(kmeans_fits[[2]], newdata = iris_data[ , 1:4])
predict(object = kmeans_fits[[2]], newdata = iris_data[ , 1:4])
predict(kmeans_fits[[2]], iris_data[ , 1:4])
iris_data[ , 6] = "test"
View(iris_data)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
View(iris_data)
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
#iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
View(kmeans_fits)
data(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
#iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
View(kmeans_fits)
kmeans_fits[[2]][["cluster"]]
kmeans_fits[[15]][["cluster"]]
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
for(i in 1:15) {
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
View(iris_data)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
data(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
data(iris)
iris_data = iris[ , 1:4] # excludes 5th column (Species)
kmeans_fits = list()
for(i in 1:15) {
kmeans_fits[[i]] = kmeans(iris_data, centers = i, iter.max = 1000)
#iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
for(i in 1:15) {
iris_data[ , 4 + i] = predict(kmeans_fits[[i]], newdata = iris_data[ , 1:4])
}
head(iris)
summary(kmeans_fits[[1]])
summary(kmeans_fits[[2]])
summary(kmeans_fits[[3]])
summary(kmeans_fits[[4]])
summary(kmeans_fits[[5]])
summary(kmeans_fits[[6]])
summary(kmeans_fits[[7]])
summary(kmeans_fits[[8]])
summary(kmeans_fits[[9]])
summary(kmeans_fits[[10]])
summary(kmeans_fits[[3]])
summary(kmeans_fits[[2]])
summary(kmeans_fits[[1]])
summary(kmeans_fits[[4]])
head(iris)
ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = factor(iris_data$V7))) +
geom_point()
ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = factor(V7))) +
geom_point()
ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = factor(V7))) +
geom_point() +
labs(color = "Cluster")
# 3 clusters
ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = factor(V7))) +
geom_point() +
labs(color = "Cluster", title = "3 Cluster Kmeans compared to Sepal measurements")
ggplot(iris_data, aes(x = Petal.Length, y = Petal.Width, color = factor(V7))) +
geom_point() +
labs(color = "Cluster", title = "3 Cluster Kmeans compared to Petal measurements")
head(iris)
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point() +
labs(color = "Species", title = "Species vs to Sepal measurements")
ggplot(iris, aes(x = Petal.Length, y = Petal.Width, color = Species)) +
geom_point() +
labs(color = "Species", title = "Species vs to Petal measurements")
iris$pred_k3 = iris_data$V7
