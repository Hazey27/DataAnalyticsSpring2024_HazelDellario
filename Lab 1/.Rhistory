geom_point()
library("keras")
library("tensorflow")
library("tidyverse")
#load dataset
mnist <- dataset_mnist()
reticulate::install_python()
library("tidyverse")
#load dataset
mnist <- dataset_mnist()
devtools::install_github("rstudio/tensorflow")
install.packages("randomForestSRC")
install.packages("ggRandomForests")
library("RandomForestSRC")
library("randomForestSRC")
library("ggRandomForests")
ìnstall.packages("randomForest")
install.packages("randomForest")
install.packages("randomForest")
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
install.packages("palmerpenguins")
library("palmerpenguins")
df = data("penguins")
df = data("penguins")
View(penguins)
View(penguins)
library("palmerpenguins")
library("palmerpenguins")
data("penguins")
data("penguins")
View(penguins)
predictors <- df[ , 1:6]
predictors <- penguins[ , 1:6]
View(predictors)
?randomForest
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguings)) #sample num of cells and select 70%
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indexes, ] #train KNN on 70% of data
train <- penguins[indices, ] #train KNN on 70% of data
test <- penguins[-indices, ]
glimpse(penguins)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train)
df = na.omit(penguins)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
print(rf)
summary(rf)
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
?predict
?randomForest::predict.randomForest
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
?predict.randomForest
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
data("penguins")
predictors <- penguins[ , 1:7]
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- randomForest::predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- randomForest::predict(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
?randomForest::predict
predictions <- predict(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
View(predictions)
?table
table(test_values, predictions)
table(test_values, predictions$aggregate)
view(predictions$aggregate)
view(test_values)
data("penguins")
penguins <- na.omit(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(test_values, predictions$aggregate)
table(as.vector(test_values), as.vector(predictions$aggregate))
data("penguins")
penguins <- na.omit(penguins)
View(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
View(test_values)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(as.vector(test_values), as.vector(predictions$aggregate))
which(is.na(penguins))
which(is.na(predictions$aggregate))
count(is.na(predictions$aggregate))
sum(is.na(predictions$aggregate))
is.na(predictions$aggregate)
view(predictions$aggregate)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
data("penguins")
penguins <- na.omit(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(as.vector(test_values), as.vector(predictions$aggregate))
view(predictions$aggregate)
View(test_values)
length(as.vector(test_values))
length(test_values)
length(test_values[ , 1])
view(as.vector(test_values))
d <- cbind(predictions$aggregate, true_values)
d <- cbind(predictions$aggregate, true_value)
test_values <- penguins[-indices, 7]
d <- cbind(predictions$aggregate, test_values)
View(d)
which(d, predictions$aggregate != sex)
which(predictions$aggregate != sex)
which(predictions$aggregate != sex, data = d)
?which
which(d$predictions$aggregate != d$sex)
d$`predictions$aggregate`
d$sex
which(d$'predictions$aggregate' != d$sex)
model <- cbind(predictions$aggregate, test_values)
which(model$'predictions$aggregate' != model$sex)
model <- cbind(predictions$aggregate, test_values) %>%
mutate(predictions = predictions$aggregate)
View(model)
which(model$predictions != model$sex)
count(which(model$predictions != model$sex))
length(which(model$predictions != model$sex))
accuracy <- length(which(model$predictions != model$sex)) / length(model$sex)
accuracy
accuracy <- 1 - length(which(model$predictions != model$sex)) / length(model$sex)
accuracy
accuracy <- length(which(model$predictions == model$sex)) / length(model$sex)
accuracy
rf
summary(rf)
View(rf)
install.packages("devtools")
library(devtools)
devtools::install_github('araastat/reprtree')
library(reprtree)
library("reprtree")
plot.getTree(rf)
install.packages("party")
#alternative method
library("party")
cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
plot(party)
View(party)
plot.reprtree(rf)
?plot.reprtree
library("reprtree")
plot.reprtree(rf)
plot.getTree(rf)
plot.reprtree(rf)
reprtree::plot.reprtree(rf)
plot.getTree(rf)
?plot.getTree
plot.getTree(rf, k = 48)
plot.getTree(rf, k = 490)
plot(party, type = "simple")
#alternative method
library("party")
party <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
plot(party, type = "simple")
?ctree
party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
?ctree_control
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
install.packages("devTools")
install.packages("devtools")
library(devtools)
devtools::install_github('araastat/reprtree')
library(reprtree)
library("tidyverse")
library("palmerpenguins")
library("randomForest")
library("tidyverse")
library("palmerpenguins")
library("reprtree")
data("penguins")
penguins <- na.omit(penguins)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
rf
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) # select 70%
train <- penguins[indices, ]
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
?predict.randomForest
View(predictions)
model <- cbind(predictions$aggregate, test_values) %>%
mutate(predictions = predictions$aggregate)
which(model$predictions != model$sex)
accuracy <- length(which(model$predictions == model$sex)) /
length(model$sex)
accuracy
plot.getTree(rf, k = 490)
plot.getTree(rf, k = 320)
#alternative method
library("party")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
plot(party.tree, type = "simple")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
#alternative method
library("party")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
dev.off
dev.off()
plot(party.tree, type = "simple")
library("tidyverse")
library("tidyverse")
library("randomForest")
library("randomForestExplainer")
install.packages("randomForestExplainer")
library("randomForestExplainer")
library("randomForestSRC")
library("ggRandomForest")
install.packages("ggRandomForest")
library("ggRandomForest")
library("ggRandomForests")
data(Boston, package = "MASS")
Boston$chas <- as.logical(Boston$chas)
str(Boston)
set.seed(125)
rmft <- randomForest(medv ~ ., data = Boston, localImp = T)
rmft
plot(rmft)
#determine ideal mtry value, mtry with least error
mtry <- tuneRF(Boston[-1], Boston$medv, ntreeTry = 500,
stepFactor = 1.5, improve = 0.01, trace = T)
best_mtry <- mtry[mtry[ , 2] == min(mtry[ , 2]), 1]
rmft_mtry <- randomForest(mdev ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry <- randomForest(medv ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry
plot(rmft_mtry)
importance(rmft_mtry)
varImpPlot(rmft_mtry)
#un the explainer
min_depth_frame <- min_depth_distribution(rmft_mtry)
head(min_depth_frame)
plot_min_depth_distribution(min_depth_frame)
plot_min_depth_distribution(min_depth_frame) #very pretty plot
plot_min_depth_distribution(min_depth_frame,
mean_sample = "relevant_trees",
k = 15)
importance_frame <- measure_importance(rmft_mtry)
importance_frame
plot_multi_way_importance(importance_frame, size_measure = "no_of_nodes")
plot_multi_way_importance(importance_frame,
x_measure = "mse_increase",
y_measure = "node_purity_increase",
size_measure = "p_value",
no_of_labels = 5)
plot_importance_ggpairs(importance_frame)
plot_importance_rankings(importance_frame)
vars <- important_variables(importance_frame,
k = 5,
measures = c("mean_min_depth", "no_of_trees"))
interactions_frame <- min_depth_interactions(rmft_mtry, vars)
plot_min_depth_interactions(interactions_frame)
interactions_frame <- min_depth_interactions(rmft_mtry, vars,
mean_sample =  "relevant_trees",
uncond_mean_sample = "relevant_trees")
plot_predict_interaction(rmft_mtry, Boston, "rm", "lstat")
rmftsrc <- rfsrc(medv ~ ., data = Boston)
plot(gg_rfsrc(rmftsrc), alpha = 0.5) + coord_cartesian(ylim = c(5, 49))
plot(gg_vimp(rmftsrc))
vars_src <- var.select(rmftsrc)
gg_md <- gg_minimal_depth(vars_src)
plot(gg_md)
gg_v <- gg_variable(rmftsrc)
xvar <- gg_md$topvars
plot(gg_v, xvar = xvar, panel = T, se = 0.95, span = 1.2, alpha = 0.4) +
labs(y = "medv", x= "")
plot(gg_v, xvar = "chas", points = F,
notch = T, alpha = 0.4) +
labs(y = "medv")
show.plots = F
partial
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T,
sorted = F,
show.plots = F)
partial
partial
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
gg_p <- gg_partial(partial)
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#variable intersection
interaction_src <- find.interaction(rmftsrc)
plot(gg_interaction(interaction_src),
xvar = gg_md$topvars, panel = T)
# Importing
library("caret")
source("~/GitHub/DataAnalyticsSpring2024_HazelDellario/Lab 1/lab_1_code.R", echo=TRUE)
source("~/GitHub/DataAnalyticsSpring2024_HazelDellario/Lab 1/lab_1_code.R", echo=TRUE)
source("~/GitHub/DataAnalyticsSpring2024_HazelDellario/Lab 1/lab_1_code.R", echo=TRUE)
lines(density(EPI_data$EPI, na.rm = TRUE, bw = 1.)) # Adds contour to histogram (try bw=“SJ”)
hist(EPI_data$EPI, breaks = seq(from = 30., to = 95., by = 1.0), prob=TRUE, main = "Histogram of EPI", xlab = "Frequency", ylab = "Density")
lines(density(EPI_data$EPI, na.rm = TRUE, bw = 1.)) # Adds contour to histogram (try bw=“SJ”)
lines(density(EPI_data$EPI, na.rm = TRUE, bw = "SJ")) # Adds contour to histogram (try bw=“SJ”)
hist(EPI_data$EPI, breaks = seq(from = 30., to = 95., by = 1.0), prob=TRUE, main = "Histogram of EPI", xlab = "Frequency", ylab = "Density")
lines(density(EPI_data$EPI, na.rm = TRUE, bw = "SJ")) # Adds contour to histogram (try bw=“SJ”)
plot_stats(EPI_2016$x2016_epi_score, 5)
ggplot(EPI_2016, aes(x = x2016_epi_score)) +
geom_bar()
ggplot(EPI_2016, aes(x = country, y = x2016_epi_score)) +
geom_count()
ggplot(EPI_2016, aes(x = country, y = x2016_epi_score)) +
geom_point()
View(EPI_2016)
View(EPI_2016)
ggplot(EPI_2016[1:10, ], aes(x = country, y = x2016_epi_score)) +
geom_point()
ggplot(EPI_2016[1:10, ], aes(x = country, y = x2016_epi_score)) +
geom_col()
ggplot(EPI_2016[1:15, ], aes(x = country, y = x2016_epi_score)) +
geom_col() +
ylim(c(0, 100))
?labs
ggplot(EPI_2016[1:15, ], aes(x = country, y = x2016_epi_score)) +
geom_col() +
ylim(c(0, 100)) +
labs(title = "EPI Scores in 2016") +
xlab("Country") +
ylab("EPI Score in 2016")
dim(EPI_2016)
ggplot(EPI_2016[1:180, ], aes(x = country, y = x2016_epi_score)) +
geom_col() +
ylim(c(0, 100)) +
labs(title = "EPI Scores in 2016") +
xlab("Country") +
ylab("EPI Score in 2016")
ggplot(EPI_2016[c(1, 180), ], aes(x = country, y = x2016_epi_score)) +
geom_col() +
ylim(c(0, 100)) +
labs(title = "EPI Scores in 2016") +
xlab("Country") +
ylab("EPI Score in 2016")
plot_stats(EPI_2016$x2016_epi_score, 5)
plot_stats(EPI_data$PopulationDensity07, 30)
?qqplot
?ppoints
?selection_tale
?selection_table
library(warbleR)
install.packages("warbleR")
library("warbleR")
library("warbleR")
#IMPORTING
library("tidyverse")
library("tuneR")
library("warbleR")
library("Rraven")
