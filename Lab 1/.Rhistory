?predict.randomForest
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
data("penguins")
predictors <- penguins[ , 1:7]
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- randomForest::predict.randomForest(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- randomForest::predict(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
?randomForest::predict
predictions <- predict(rf,
test_values,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
View(predictions)
?table
table(test_values, predictions)
table(test_values, predictions$aggregate)
view(predictions$aggregate)
view(test_values)
data("penguins")
penguins <- na.omit(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(test_values, predictions$aggregate)
table(as.vector(test_values), as.vector(predictions$aggregate))
data("penguins")
penguins <- na.omit(penguins)
View(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
View(test_values)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(as.vector(test_values), as.vector(predictions$aggregate))
which(is.na(penguins))
which(is.na(predictions$aggregate))
count(is.na(predictions$aggregate))
sum(is.na(predictions$aggregate))
is.na(predictions$aggregate)
view(predictions$aggregate)
library("randomForest")
library("randomForestSRC")
library("ggRandomForests")
library("tidyverse")
library("palmerpenguins")
data("penguins")
penguins <- na.omit(penguins)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) #sample num of cells and select 70%
train <- penguins[indices, ] #train KNN on 70% of data
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
table(as.vector(test_values), as.vector(predictions$aggregate))
view(predictions$aggregate)
View(test_values)
length(as.vector(test_values))
length(test_values)
length(test_values[ , 1])
view(as.vector(test_values))
d <- cbind(predictions$aggregate, true_values)
d <- cbind(predictions$aggregate, true_value)
test_values <- penguins[-indices, 7]
d <- cbind(predictions$aggregate, test_values)
View(d)
which(d, predictions$aggregate != sex)
which(predictions$aggregate != sex)
which(predictions$aggregate != sex, data = d)
?which
which(d$predictions$aggregate != d$sex)
d$`predictions$aggregate`
d$sex
which(d$'predictions$aggregate' != d$sex)
model <- cbind(predictions$aggregate, test_values)
which(model$'predictions$aggregate' != model$sex)
model <- cbind(predictions$aggregate, test_values) %>%
mutate(predictions = predictions$aggregate)
View(model)
which(model$predictions != model$sex)
count(which(model$predictions != model$sex))
length(which(model$predictions != model$sex))
accuracy <- length(which(model$predictions != model$sex)) / length(model$sex)
accuracy
accuracy <- 1 - length(which(model$predictions != model$sex)) / length(model$sex)
accuracy
accuracy <- length(which(model$predictions == model$sex)) / length(model$sex)
accuracy
rf
summary(rf)
View(rf)
install.packages("devtools")
library(devtools)
devtools::install_github('araastat/reprtree')
library(reprtree)
library("reprtree")
plot.getTree(rf)
install.packages("party")
#alternative method
library("party")
cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
plot(party)
View(party)
plot.reprtree(rf)
?plot.reprtree
library("reprtree")
plot.reprtree(rf)
plot.getTree(rf)
plot.reprtree(rf)
reprtree::plot.reprtree(rf)
plot.getTree(rf)
?plot.getTree
plot.getTree(rf, k = 48)
plot.getTree(rf, k = 490)
plot(party, type = "simple")
#alternative method
library("party")
party <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
plot(party, type = "simple")
?ctree
party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
?ctree_control
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
install.packages("devTools")
install.packages("devtools")
library(devtools)
devtools::install_github('araastat/reprtree')
library(reprtree)
library("tidyverse")
library("palmerpenguins")
library("randomForest")
library("tidyverse")
library("palmerpenguins")
library("reprtree")
data("penguins")
penguins <- na.omit(penguins)
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
rf
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
#create training and testing data set
indices <- sample(1:nrow(penguins), size = 0.7 * nrow(penguins)) # select 70%
train <- penguins[indices, ]
test_predictors <- penguins[-indices, 1:6]
test_values <- penguins[-indices, 7]
rf <- randomForest(sex ~ species + island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = train,
na.action = na.omit)
rf
summary(rf)
predictions <- predict(rf,
test_predictors,
type = "response",
norm.votes = TRUE,
predict.all = TRUE,
nodes = TRUE)
?predict.randomForest
View(predictions)
model <- cbind(predictions$aggregate, test_values) %>%
mutate(predictions = predictions$aggregate)
which(model$predictions != model$sex)
accuracy <- length(which(model$predictions == model$sex)) /
length(model$sex)
accuracy
plot.getTree(rf, k = 490)
plot.getTree(rf, k = 320)
#alternative method
library("party")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
plot(party.tree, type = "simple")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
#alternative method
library("party")
#party.forest <- cforest(sex ~ ., data=train, controls=cforest_control(mtry=2, mincriterion=0))
party.tree <- ctree(sex ~ ., data=train, controls=ctree_control(mtry=2, mincriterion=0))
plot(party.tree, type = "simple")
dev.off
dev.off()
plot(party.tree, type = "simple")
library("tidyverse")
library("tidyverse")
library("randomForest")
library("randomForestExplainer")
install.packages("randomForestExplainer")
library("randomForestExplainer")
library("randomForestSRC")
library("ggRandomForest")
install.packages("ggRandomForest")
library("ggRandomForest")
library("ggRandomForests")
data(Boston, package = "MASS")
Boston$chas <- as.logical(Boston$chas)
str(Boston)
set.seed(125)
rmft <- randomForest(medv ~ ., data = Boston, localImp = T)
rmft
plot(rmft)
#determine ideal mtry value, mtry with least error
mtry <- tuneRF(Boston[-1], Boston$medv, ntreeTry = 500,
stepFactor = 1.5, improve = 0.01, trace = T)
best_mtry <- mtry[mtry[ , 2] == min(mtry[ , 2]), 1]
rmft_mtry <- randomForest(mdev ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry <- randomForest(medv ~ ., data = Boston, mtry = best_mtry,
importance = T)
rmft_mtry
plot(rmft_mtry)
importance(rmft_mtry)
varImpPlot(rmft_mtry)
#un the explainer
min_depth_frame <- min_depth_distribution(rmft_mtry)
head(min_depth_frame)
plot_min_depth_distribution(min_depth_frame)
plot_min_depth_distribution(min_depth_frame) #very pretty plot
plot_min_depth_distribution(min_depth_frame,
mean_sample = "relevant_trees",
k = 15)
importance_frame <- measure_importance(rmft_mtry)
importance_frame
plot_multi_way_importance(importance_frame, size_measure = "no_of_nodes")
plot_multi_way_importance(importance_frame,
x_measure = "mse_increase",
y_measure = "node_purity_increase",
size_measure = "p_value",
no_of_labels = 5)
plot_importance_ggpairs(importance_frame)
plot_importance_rankings(importance_frame)
vars <- important_variables(importance_frame,
k = 5,
measures = c("mean_min_depth", "no_of_trees"))
interactions_frame <- min_depth_interactions(rmft_mtry, vars)
plot_min_depth_interactions(interactions_frame)
interactions_frame <- min_depth_interactions(rmft_mtry, vars,
mean_sample =  "relevant_trees",
uncond_mean_sample = "relevant_trees")
plot_predict_interaction(rmft_mtry, Boston, "rm", "lstat")
rmftsrc <- rfsrc(medv ~ ., data = Boston)
plot(gg_rfsrc(rmftsrc), alpha = 0.5) + coord_cartesian(ylim = c(5, 49))
plot(gg_vimp(rmftsrc))
vars_src <- var.select(rmftsrc)
gg_md <- gg_minimal_depth(vars_src)
plot(gg_md)
gg_v <- gg_variable(rmftsrc)
xvar <- gg_md$topvars
plot(gg_v, xvar = xvar, panel = T, se = 0.95, span = 1.2, alpha = 0.4) +
labs(y = "medv", x= "")
plot(gg_v, xvar = "chas", points = F,
notch = T, alpha = 0.4) +
labs(y = "medv")
show.plots = F
partial
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T,
sorted = F,
show.plots = F)
partial
partial
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
gg_p <- gg_partial(partial)
plot(gg_p, panel = T) +
labs(y = "medv", x = "")
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#partial dependence
partial <- plot.variable(rmftsrc,
xvar = gg_md$topvars,
partial = T) #,
#variable intersection
interaction_src <- find.interaction(rmftsrc)
plot(gg_interaction(interaction_src),
xvar = gg_md$topvars, panel = T)
library("caret")
library("janitor")
library("MASS")
library("tidyverse")
setwd("C:/Users/hazeldellario/Desktop/Homework/data_analysis")
EPI_data <- read.csv("2010EPI_data.csv", header = TRUE, skip = 1, na.strings = "..")
#Set columns to correct data types
EPI_data$code <- as.integer(EPI_data$code)
EPI_data$GDPCAP07 <- as.double(EPI_data$GDPCAP07)
EPI_data$Population07 <- as.double(EPI_data$Population07)
EPI_data <- na.omit(EPI_data)
summary(EPI_data, na.rm = TRUE)
boxplot(EPI_data$EPI)
stem(EPI_data$EPI)
hist(EPI_data$EPI)
hist(EPI_data$EPI, breaks = seq(from = 30., to = 95., by = 1.0), prob=TRUE, main = "Histogram of EPI", xlab = "Frequency", ylab = "Density")
lines(density(EPI_data$EPI, na.rm = TRUE, bw = 1.)) # Adds contour to histogram (try bw=“SJ”)
rug(EPI_data$EPI) #shows x values over x axis
# Determine distribution of data
plot(ecdf(EPI_data$EPI), do.points = FALSE, verticals = TRUE)
par(pty="s")
qqnorm(EPI_data$EPI)
qqline(EPI_data$EPI) #qq plot with line of best fit; linear regression
# qqplot from generating distribution
x<-seq(30,95,1)
qqplot(qt(ppoints(250), df= 5), x, xlab= "Q-Q plot for t dsn")
qqline(x)
plot_stats <- function(data, from = 30, to = 95, step = 1) {
hist(data, breaks = seq(from, to, step), prob=TRUE, #main = paste("Histogram of", data), #creates a title for every data point :_(
xlab = "Frequency", ylab = "Density")
lines(density(data, na.rm = TRUE, bw = "SJ")) # Adds contour to histogram (try bw=“SJ”)
rug(data) #shows x values over x axis
# Determine distribution of data
plot(ecdf(data), do.points = FALSE, verticals = TRUE)
par(pty="s")
qqnorm(data)
qqline(data) #qq plot with line of best fit; linear regression
# qqplot from generating distribution
x<-seq(sequence)
qqplot(qt(ppoints(250), df= 5), x, xlab= "Q-Q plot for t dsn")
qqline(x)
}
plot_stats(EPI_data$PopulationDensity07, round(min(EPI_data$PopulationDensity07), digits = -2), round(max(EPI_data$PopulationDensity07 + 50), digits = -2), 30)
plot_stats(EPI_data$GDPCAP07, round(min(EPI_data$GDPCAP07) - 500, digits = -3), round(max(EPI_data$GDPCAP07)+ 500, digits = -3), 1000)
plot_stats(EPI_data$DALY, round(min(EPI_data$DALY) - 5, digits = -2), round(max(EPI_data$DALY)+ 5, digits = -2), 10)
plot_stats(EPI_data$WATER_H, round(min(EPI_data$WATER_H) - 5, digits = -2), round(max(EPI_data$WATER_H)+ 5, digits = -2), 10)
boxplot(EPI_data$EPI, EPI_data$DALY)
boxplot(EPI_data$EPI, EPI_data$ENVHEALTH)
boxplot(EPI_data$EPI, EPI_data$ECOSYSTEM)
boxplot(EPI_data$EPI, EPI_data$AIR_H)
boxplot(EPI_data$EPI, EPI_data$WATER_H)
boxplot(EPI_data$EPI, EPI_data$AIR_E)
boxplot(EPI_data$EPI, EPI_data$WATER_E)
boxplot(EPI_data$EPI, EPI_data$BIODIVERSITY)
filter_GEO <- function(subregion) {
#return(EPI_data[ , EPI_data$GEO_subregion == subregion]) #gives the wrong dimension matrix; excludes a ton of variables and adds rows?
newvar <- EPI_data %>%
filter(GEO_subregion == subregion)
return(newvar)
}
EPI_South_Asia <- filter_GEO("South Asia")
EPI_Caribbean <- filter_GEO("Caribbean")
EPI_NA <- filter_GEO("North America")
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI)
boxplot(EPI_South_Asia$EPI, EPI_NA$EPI)
boxplot(EPI_Caribbean$EPI, EPI_NA$EPI)
boxplot(EPI_South_Asia$PopulationDensity07, EPI_Caribbean$PopulationDensity07)
boxplot(EPI_South_Asia$PopulationDensity07, EPI_NA$PopulationDensity07)
boxplot(EPI_Caribbean$PopulationDensity07, EPI_NA$PopulationDensity07)
EPI_data$LandLock <- as.logical(EPI_data$Landlock)
EPILand<-EPI_data[EPI_data$Landlock != 1]
Eland <-EPILand[!is.na(EPILand)] %>%
as.double() %>%
na.omit()
summary(Eland) #a few incredibly extreme outliers (mean and median differ by 2.0e+06)
plot(Eland) #there is just 1 value at 2.6e+09 and just two at ~1.0e+09
#lets cut off at 5e+08 for now; removes only 3 values
Eland_no_outliers <- Eland[-which(Eland > 5.0e+08)]
hist(Eland_no_outliers) #still a ton of outliers, but I don't think we should remove more than a few points. Otherwise we're cherrypicking data
hist(Eland_no_outliers, seq(-10, 5.0e+08, 2e+07), prob=TRUE) #this one still looks awful
length(which(Eland > 1e+08)) #only 9 values above 1.0e+08. Will exclude those
Eland_1e8 <- Eland[-which(Eland > 1e+08)]
hist(Eland_1e8) #makes a better histogram
hist(Eland_1e8, seq(-10, 1.0e+08, 5e+06), prob=TRUE) #this still looks terrible but that just might be how the data looks honestly
hist(Eland_1e8, prob = T) # automatic binning in R does a better job creating a picture of the data
lines(density(Eland_1e8, bw = "SJ")) #this looks awful; I can't get it to look better. I think the distribution of the data is too off for this to work
rug(Eland_1e8)
range(EPI_data$No_surface_water) # Only 0 so graphing would not be interesting
boxplot(EPI_data$EPI, EPI_data$DALY)
boxplot(EPI_data$EPI, EPI_data$ENVHEALTH)
boxplot(EPI_data$EPI, EPI_data$ECOSYSTEM)
boxplot(EPI_data$EPI, EPI_data$AIR_H)
boxplot(EPI_data$EPI, EPI_data$WATER_H)
boxplot(EPI_data$EPI, EPI_data$AIR_E) # surprisingly different
boxplot(EPI_data$EPI, EPI_data$WATER_E) # also quite different
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI)
boxplot(EPI_South_Asia$EPI, EPI_NA$EPI)
boxplot(EPI_Caribbean$EPI, EPI_NA$EPI)
boxplot(EPI_South_Asia$PopulationDensity07, EPI_Caribbean$PopulationDensity07)
?boxplot
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, ylim = c(0, 100)) # Caribbean has great EPI, South Asia has poor EPI (median 60)
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, EPI_NA$EPI,  ylim = c(0, 100)) # Caribbean has pretty good EPI, South Asia has poor EPI (median 60)
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, EPI_NA$EPI,  ylim = c(0, 100), xlabs = c("South Asia", "Caribbean", "North America")) # Caribbean has pretty good EPI, South Asia has poor EPI (median 60)
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, EPI_NA$EPI,  ylim = c(0, 100), xlab = c("South Asia", "Caribbean", "North America")) # Caribbean has pretty good EPI, South Asia has poor EPI (median 60)
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, EPI_NA$EPI,  ylim = c(0, 100), xlab = c("Country"), ylab = "EPI") # Caribbean has pretty good EPI, South Asia has poor EPI (median 60)
?bxp
boxplot(EPI_South_Asia$PopulationDensity07, EPI_Caribbean$PopulationDensity07, EPI_NA$PopulationDensity07)
boxplot(EPI_South_Asia$PopulationDensity07, EPI_Caribbean$PopulationDensity07, EPI_NA$PopulationDensity07) # NA has lowest pop dens by far
EPI_data$LandLock <- as.logical(EPI_data$Landlock)
EPILand<-EPI_data[EPI_data$Landlock != 1]
Eland <-EPILand[!is.na(EPILand)] %>%
as.double() %>%
na.omit()
summary(Eland) #a few incredibly extreme outliers (mean and median differ by 2.0e+06)
plot(Eland) #there is just 1 value at 2.6e+09 and just two at ~1.0e+09
#lets cut off at 5e+08 for now; removes only 3 values
Eland_no_outliers <- Eland[-which(Eland > 5.0e+08)]
hist(Eland_no_outliers) #still a ton of outliers, but I don't think we should remove more than a few points. Otherwise we're cherrypicking data
hist(Eland_no_outliers, seq(-10, 5.0e+08, 2e+07), prob=TRUE) #this one still looks awful
range(Eland_no_outliers)
range(Eland_1e8)
hist(Eland_1e8, seq(-10, 1.0e+08, 1e+07), prob=TRUE) #this still looks terrible but that just might be how the data looks honestly
hist(Eland_1e8, seq(-10, 1.0e+08, 1e+06), prob=TRUE) #this still looks terrible but that just might be how the data looks honestly
hist(Eland_1e8, seq(-10, 1.0e+08, 2e+06), prob=TRUE) #this still looks terrible but that just might be how the data looks honestly
boxplot(EPI_South_Asia$EPI, EPI_Caribbean$EPI, EPI_NA$EPI,  ylim = c(0, 100), xlab = c("Country"), ylab = "EPI") # Caribbean has pretty good EPI, South Asia has poor EPI (median 60)
boxplot(EPI_South_Asia$PopulationDensity07, EPI_Caribbean$PopulationDensity07, EPI_NA$PopulationDensity07) # NA has lowest pop dens by far
boxplot(EPI_South_Asia$EPI, EPI_South_Asia$PopulationDensity07)
hist(Eland_1e8, prob = T) # automatic binning in R does a better job creating a picture of the data
lines(density(Eland_1e8, bw = "SJ")) #this looks awful; I can't get it to look better. I think the distribution of the data is too off for this to work
?lines
range(EPI_data$No_surface_water) # Only 0 so graphing would not be interesting
print(EPI_data$No_surface_water)
